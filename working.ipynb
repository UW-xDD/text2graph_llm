{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from text2graph.llm import ask_llm, OpenSourceModel\n",
    "from text2graph import lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Supported open-source (OSS) models: {[m.value for m in OpenSourceModel]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `mixtral`: top open-source llm model based on [chatbot arean](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard), ELO: 1118 ~= GPT3.5 turbo\n",
    "- `openhermes`: decent open-source small-ish (7b) model, ELO: 1078 (won't test on this yet, Bill is using this with somewhat decent results in similar use case?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract locations based-on Shanan's example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEGATIVE_EXAMPLE = \"\"\"\n",
    "This community-vetted CO2 syn- thesis represents the most reliable data avail- able to date and a means to improve our understanding of past changes in global cli- mate and carbon cycling as well as organismal evolution. However, this effort is still incomplete. Data remain sparse during the earlier part of the record and in some instances are domi- nated by estimates from a single proxy system. Generating a paleo-CO2 record with even greater confidence will require further research using multiple proxies to fill in data gaps and increase overall data resolution, resolve discrepancies between estimates from contemporaneous proxy analyses, reduce uncertainty o\n",
    "\"\"\"\n",
    "\n",
    "POSITIVE_EXAMPLE = \"\"\"\n",
    "The top of the Sauk megasequence in Minnesota is at the unconformable contact of the Shakopee Formation with the St. Peter Sandstone. Younger rocks are present beneath the St. Peter Sandstone on the southern and east- ern flanks of the Ozark dome, where the upper Sauk succession includes the Roubidoux, Jefferson City, Cotter, Powell – Smithville – Black Rock, and Everton units in that stratigraphic order (Ethington et al., 2012; Palmer et al., 2012). The Shakopee Formation is equivalent to some lower part of this succession, but sparse inverte- brate faunas and long-ranging conodonts in these units preclude correlation with high resolution. The Jasper Member of the Everton Formation of northern Arkansas contains conodonts of the Histiodella holodentata Biozone, which demonstrates the latest early Whiterockian age for the top of the rocks of the GACB in that region. No faunal evidence is available there for the age of the base of the St. Peter Sandstone. The boundary between the Sauk and Tippecanoe megasequences may be a cor- relative conformity in the Reelfoot rift of southeastern Missouri and northeastern Missouri, but this has not been demonstrated.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In [Shanan's example](https://chat.openai.com/share/d14a5163-ddb4-4f28-b6d4-bbf4839f62cb), he forced the model to perform a guided 2 steps chain-of-thought.\n",
    "\n",
    "1. What locations are mentioned in the following paragraph?\n",
    "2. What geological entities are associated with those locations?\n",
    "\n",
    "We can try to make an exact replication on our OSS models.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = \"What locations are mentioned in the following paragraph?\"\n",
    "q2 = \"What geological entities are associated with those locations?\"\n",
    "\n",
    "message = {\"role\": \"user\", \"content\": f\"{q1}\\n{NEGATIVE_EXAMPLE}\"}\n",
    "response = ask_llm(messages=[message], model=\"mixtral\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, this is the exact return from Shanan's example:\n",
    "```\n",
    "The paragraph does not mention specific locations. Instead, it discusses data synthesis and the need for further research to improve our understanding of past changes in global climate and carbon cycling. Therefore, specific locations are not mentioned in this paragraph.\n",
    "``````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somewhat close enough, perhaps GPT prefers a bit simpler wordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = {\"role\": \"user\", \"content\": f\"{q1}\\n{POSITIVE_EXAMPLE}\"}\n",
    "response = ask_llm(messages=[message], model=\"mixtral\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, this is the exact return from Shanan's example:\n",
    "```\n",
    "The locations mentioned in the paragraph are:\n",
    "\n",
    "Minnesota\n",
    "Ozark dome (southern and eastern flanks)\n",
    "Northern Arkansas\n",
    "Reelfoot rift (southeastern Missouri and northeastern Missouri)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate the conversation with follow-up question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [message]  # Last message\n",
    "messages.append({\"role\": \"assistant\", \"content\": response})  # Last response\n",
    "messages.append({\"role\": \"user\", \"content\": q2})\n",
    "response = ask_llm(messages=messages, model=\"mixtral\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, this is the exact return from Shanan's example:\n",
    "```\n",
    "The geological entities associated with the mentioned locations are:\n",
    "\n",
    "Minnesota: Sauk megasequence, Shakopee Formation, St. Peter Sandstone.\n",
    "Ozark dome (southern and eastern flanks): Sauk megasequence, Roubidoux Formation, Jefferson City Formation, Cotter Formation, Powell-Smithville-Black Rock Formation, Everton Formation.\n",
    "Northern Arkansas: Everton Formation, Jasper Member.\n",
    "Reelfoot rift (southeastern Missouri and northeastern Missouri): Sauk megasequence, Tippecanoe megasequence.\n",
    "``````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interim conclusion:\n",
    "\n",
    "In this particular use case, perhaps `mixtral` is suffice?\n",
    "\n",
    "More issues to consider:\n",
    "\n",
    "1. Can we speed it up a bit by Reducing query round trip from 2 to 1?\n",
    "1. Can we return json format instead of plain text?\n",
    "1. How to lemmatize location or geo-entities? (Try traditional methods first, then we can try embedding distance based method)\n",
    "1. Test on larger test set. Use a subset of Devesh's test set. Perhaps 30 examples first, scale up later if we reach a good result. Need manual labeling. (Devesh's test set don't have labels) \n",
    "1. Serve API endpoint for user testing.\n",
    "1. Serve Demo for user testing.\n",
    "\n",
    "Backlog low-priority items:\n",
    "\n",
    "1. Geo-coding for extracted locations.\n",
    "1. How to use the Stratigraphy and Lithology list from MacroStrat?\n",
    "1. Multi-agent setup to improve quality.\n",
    "1. Logging and monitoring: Collect user feedback for fine-tuning (e.g., prompt-tune (interactive or generative) or Direct Preference Optimization (need around 20k labeled data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed up experiment: Zero-shot CoT\n",
    "\n",
    "- Borrowing some system prompt idea from Sky's [ta2-extraction example](https://github.com/DARPA-CRITICALMAAS/ta2-extraction/blob/master/prompts.py)\n",
    "- Try to reduce round-trip from 2 to 1.\n",
    "- Improve response format from free text to json-like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(text: str) -> list[dict]:\n",
    "    \"\"\"V0 geo-location prompting.\"\"\"\n",
    "\n",
    "    system_prompt = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a geology expert and you are very good in understanding mining reports. Think step by step: What locations are mentioned in the following paragraph? and What geological entities are associated with those locations? Return in json format like this: {'location1': ['entity1', 'entity2', ...], 'location2': ['entity3', 'entity4', ...]}. Return an empty dictionary if there is no location.\",\n",
    "    }\n",
    "    user_prompt = {\"role\": \"user\", \"content\": text}\n",
    "    return [system_prompt, user_prompt]\n",
    "\n",
    "\n",
    "def experiment1(text: str) -> str:\n",
    "    \"\"\"V0 geo-location experiment.\"\"\"\n",
    "    response = ask_llm(messages=get_prompt(text), model=\"mixtral\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(experiment1(NEGATIVE_EXAMPLE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(experiment1(POSITIVE_EXAMPLE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, this is the exact return from Shanan's example:\n",
    "```\n",
    "The geological entities associated with the mentioned locations are:\n",
    "\n",
    "Minnesota: Sauk megasequence, Shakopee Formation, St. Peter Sandstone.\n",
    "Ozark dome (southern and eastern flanks): Sauk megasequence, Roubidoux Formation, Jefferson City Formation, Cotter Formation, Powell-Smithville-Black Rock Formation, Everton Formation.\n",
    "Northern Arkansas: Everton Formation, Jasper Member.\n",
    "Reelfoot rift (southeastern Missouri and northeastern Missouri): Sauk megasequence, Tippecanoe megasequence.\n",
    "``````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quality check talking points. \n",
    "\n",
    "- should `younger rocks` counts as geo-entity? If yes -> `mixtral` wins\n",
    "- `Histiodella holodentata Biozone` is a geo-entity? If yes -> `mixtral` wins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Micro testset (n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run once\n",
    "# critical_maas_knowledge_graph_testset = pd.read_parquet(\"data/formation_sample.parquet.gzip\")\n",
    "# testset_micro = critical_maas_knowledge_graph_testset.sample(30)\n",
    "# testset_micro.to_parquet(\"data/testset_micro.parquet.gzip\", compression=\"gzip\")\n",
    "\n",
    "testset_micro = pd.read_parquet(\"data/testset_micro.parquet.gzip\")\n",
    "testset_micro.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"note\": \"V0 geo-location experiment.\",\n",
    "    \"testset_path\": \"data/testset_micro.parquet.gzip\",\n",
    "    \"input\": [],\n",
    "    \"output\": [],\n",
    "}\n",
    "\n",
    "for i, row in testset_micro.iterrows():\n",
    "    input = row[\"paragraph\"]\n",
    "    output = experiment1(input)\n",
    "    results[\"input\"].append(input)\n",
    "    results[\"output\"].append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_output(index: int, results: dict) -> None:\n",
    "    print(f\"Input: {results['input'][index]}\")\n",
    "    print()\n",
    "    print(f\"Output: {results['output'][index]}\")\n",
    "\n",
    "\n",
    "for i in range(30):\n",
    "    print_output(i, results)\n",
    "    print(\"=\" * 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization experiment (Somewhat not working yet, can skip for now)\n",
    "\n",
    "Problem statement: The current geographic details and entities are overly specific for generating an aggregated graph. We must simplify them into broader terms, which will then serve as the basis for the nodes in the knowledge graph.\n",
    "\n",
    "tl;dr;\n",
    "\n",
    "- traditional methods don't work, they are more design for word level lemmatization, not phrase level.\n",
    "\n",
    "Options:\n",
    "\n",
    "1. nltk\n",
    "1. spacy\n",
    "1. embedding distance\n",
    "1. llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_locations = set()\n",
    "for r in results[\"output\"]:\n",
    "    try:\n",
    "        test_locations.update(json.loads(r).keys())\n",
    "    except json.JSONDecodeError:\n",
    "        print(r)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note to self: TODO: need better json format.\n",
    "\n",
    "- \",\" in location\n",
    "- other special characters in location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_locations = list(test_locations)\n",
    "print(test_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk = lemmatizer.NLTK()\n",
    "spacy = lemmatizer.Spacy()\n",
    "llm = lemmatizer.LLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lemma = pd.DataFrame(\n",
    "    {\n",
    "        \"locations\": test_locations,\n",
    "        \"nltk\": [nltk.lemmatize(location) for location in test_locations],\n",
    "        \"spacy\": [spacy.lemmatize(location) for location in test_locations],\n",
    "        \"llm\": [llm.lemmatize(location) for location in test_locations],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should have much room for improvement..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
